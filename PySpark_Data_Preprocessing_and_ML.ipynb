{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java version \"24.0.2\" 2025-07-15\n",
      "Java(TM) SE Runtime Environment (build 24.0.2+12-54)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 24.0.2+12-54, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24690,
     "status": "ok",
     "timestamp": 1755879606736,
     "user": {
      "displayName": "Nilay Karade",
      "userId": "16635576202550176479"
     },
     "user_tz": -330
    },
    "id": "Fs7qEKnaQ-vx",
    "outputId": "a7f0d6db-58e6-4fbd-ec47-2a555724eb3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Install Java Development kit for Spark\n",
    "#!apt-get install openjdk-8-jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1755879606753,
     "user": {
      "displayName": "Nilay Karade",
      "userId": "16635576202550176479"
     },
     "user_tz": -330
    },
    "id": "OZjlf3HKRDqe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#Set the JAVA_HOME env variable\n",
    "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1755879606817,
     "user": {
      "displayName": "Nilay Karade",
      "userId": "16635576202550176479"
     },
     "user_tz": -330
    },
    "id": "hfO9jTv5RMiT",
    "outputId": "79f974f6-3dcc-44a4-f22b-a5ec688c8efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#Current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1755879607114,
     "user": {
      "displayName": "Nilay Karade",
      "userId": "16635576202550176479"
     },
     "user_tz": -330
    },
    "id": "QUCVpOgERNYU",
    "outputId": "58900ab5-ec5a-4378-a950-64f041fcfa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-8-openjdk-amd64\n"
     ]
    }
   ],
   "source": [
    "!echo $JAVA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\pc\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install PySpark with latest version\n",
    "#!pip install pyspark==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pR1IX0t575Z9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudpickle in c:\\users\\pc\\anaconda3\\lib\\site-packages (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1755879675377,
     "user": {
      "displayName": "Nilay Karade",
      "userId": "16635576202550176479"
     },
     "user_tz": -330
    },
    "id": "K5iqk-aemt1n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fEOtocZARcLe"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXHV9CAMCEWn"
   },
   "source": [
    "Foundational Code Snippets StringIndexer\n",
    "\n",
    "StringIndexer assigns indices to categories based on how often they appear in the input column. The category that occurs most frequently gets the lowest index (0.0), the next most frequent gets the next index (1.0), and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzefXAa1BtZ-",
    "outputId": "ca33f936-ef3f-42bd-bf43-fb9f8f7548f9"
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"StringIndexerExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = spark.createDataFrame([\n",
    "    (0, \"cat\"),\n",
    "    (1, \"dog\"),\n",
    "    (2, \"dog\"),\n",
    "    (3, \"cat\"),\n",
    "    (4, \"rabbit\"),\n",
    "    (5, \"dog\")\n",
    "], [\"id\", \"animal\"])\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gCSsAGVCSDS",
    "outputId": "bafedbef-630b-49bc-b63e-9511a7636bfc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"animal\", outputCol=\"animalIndex\")\n",
    "\n",
    "# Fit the indexer model and transform the data\n",
    "indexed_data = indexer.fit(data).transform(data)\n",
    "indexed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJ1ABWhjINHm"
   },
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "\n",
    "In PySpark, OneHotEncoder is used to convert categorical variables into a binary (one-hot) encoded format, which is often necessary for machine learning algorithms. It converts the categorical column into multiple columns, each representing one category as a binary value (0 or 1).\n",
    "\n",
    "\n",
    "In PySpark, OHE returns a sparse vector which is generally represented as:\n",
    "\n",
    "\n",
    "(size, [indices], [values])\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "size is the total number of categories.\n",
    "\n",
    "indices is a list of positions where the vector has non-zero elements.\n",
    "\n",
    "values is a list of the actual non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-g_V1zo7DtFN",
    "outputId": "e1fa133b-aae4-4452-9e73-e131925c7caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+-------------+\n",
      "| id|animal|animalIndex|    animalVec|\n",
      "+---+------+-----------+-------------+\n",
      "|  0|   cat|        1.0|(3,[1],[1.0])|\n",
      "|  1|   dog|        0.0|(3,[0],[1.0])|\n",
      "|  2|   dog|        0.0|(3,[0],[1.0])|\n",
      "|  3|   cat|        1.0|(3,[1],[1.0])|\n",
      "|  4|rabbit|        2.0|(3,[2],[1.0])|\n",
      "|  5|   dog|        0.0|(3,[0],[1.0])|\n",
      "+---+------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OneHotEncoder - Convert the indexed column to one-hot encoded format\n",
    "encoder = OneHotEncoder(inputCol=\"animalIndex\", outputCol=\"animalVec\",dropLast=False)\n",
    "encoded_data = encoder.fit(indexed_data).transform(indexed_data)\n",
    "encoded_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9arq9Y62Mvld"
   },
   "source": [
    "#VectorAssembler\n",
    "VectorAssembler in PySpark is a feature transformer used to combine multiple columns into a single vector column. It is particularly useful in machine learning pipelines where models expect input features to be in the form of vectors. The output of VectorAssembler can then be fed into machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEaP4WqcMqda",
    "outputId": "50af0f9c-6d7f-4a95-80fd-7ecf87867b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+----------+\n",
      "| id| age|gender|experience|\n",
      "+---+----+------+----------+\n",
      "|  0|18.0|   1.0|       5.0|\n",
      "|  1|20.0|   0.0|       3.0|\n",
      "|  2|22.0|   1.0|       8.0|\n",
      "|  3|25.0|   0.0|       2.0|\n",
      "+---+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"VectorAssemblerExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = spark.createDataFrame([\n",
    "    (0, 18.0, 1.0, 5.0),\n",
    "    (1, 20.0, 0.0, 3.0),\n",
    "    (2, 22.0, 1.0, 8.0),\n",
    "    (3, 25.0, 0.0, 2.0),\n",
    "], [\"id\", \"age\", \"gender\", \"experience\"])\n",
    "\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnF-55gLMqcE",
    "outputId": "7f9c0c2c-b5fa-4b65-ff82-c3938afd3a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+----------+--------------+\n",
      "| id| age|gender|experience|      features|\n",
      "+---+----+------+----------+--------------+\n",
      "|  0|18.0|   1.0|       5.0|[18.0,1.0,5.0]|\n",
      "|  1|20.0|   0.0|       3.0|[20.0,0.0,3.0]|\n",
      "|  2|22.0|   1.0|       8.0|[22.0,1.0,8.0]|\n",
      "|  3|25.0|   0.0|       2.0|[25.0,0.0,2.0]|\n",
      "+---+----+------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"age\", \"gender\", \"experience\"], outputCol=\"features\")\n",
    "\n",
    "# Step 2: Apply VectorAssembler to transform the data\n",
    "output = assembler.transform(data)\n",
    "\n",
    "# Display the output with the combined feature vector\n",
    "output.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-JB1QhDMqI1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qV_5h5puqR2b",
    "outputId": "8a5fde68-5c6c-4742-d622-9e44cf621c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+----------+------+\n",
      "| id| age|gender|experience|salary|\n",
      "+---+----+------+----------+------+\n",
      "|  0|18.0|  male|       5.0| 35000|\n",
      "|  1|20.0|female|       3.0| 45000|\n",
      "|  2|22.0|  male|       8.0| 58000|\n",
      "|  3|25.0|female|       2.0| 62000|\n",
      "+---+----+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Create Spark session\n",
    "spark = SparkSession.builder.appName(\"PipelineWithOHEExample\").getOrCreate()\n",
    "\n",
    "# Sample data (including a categorical column)\n",
    "data = spark.createDataFrame([\n",
    "    (0, 18.0, \"male\", 5.0, 35000),\n",
    "    (1, 20.0, \"female\", 3.0, 45000),\n",
    "    (2, 22.0, \"male\", 8.0, 58000),\n",
    "    (3, 25.0, \"female\", 2.0, 62000),\n",
    "], [\"id\", \"age\", \"gender\", \"experience\", \"salary\"])\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fW8hM8oKel7",
    "outputId": "2c0e7f87-9dbc-44d3-aecc-b4febcf03e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+----------+------+-----------+-------------+--------------+------------------+\n",
      "| id| age|gender|experience|salary|genderIndex|    genderOHE|      features|        prediction|\n",
      "+---+----+------+----------+------+-----------+-------------+--------------+------------------+\n",
      "|  0|18.0|  male|       5.0| 35000|        1.0|    (1,[],[])|[18.0,0.0,5.0]| 35000.00000000013|\n",
      "|  1|20.0|female|       3.0| 45000|        0.0|(1,[0],[1.0])|[20.0,1.0,3.0]|45000.000000000306|\n",
      "|  2|22.0|  male|       8.0| 58000|        1.0|    (1,[],[])|[22.0,0.0,8.0]| 57999.99999999991|\n",
      "|  3|25.0|female|       2.0| 62000|        0.0|(1,[0],[1.0])|[25.0,1.0,2.0]| 61999.99999999968|\n",
      "+---+----+------+----------+------+-----------+-------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Use StringIndexer to convert the categorical column 'gender' to numerical index\n",
    "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\n",
    "\n",
    "# Step 3: Use OneHotEncoder to encode the indexed gender column into a vector\n",
    "encoder = OneHotEncoder(inputCol=\"genderIndex\", outputCol=\"genderOHE\")\n",
    "\n",
    "# Step 4: Use VectorAssembler to combine the feature columns into a single vector\n",
    "assembler = VectorAssembler(inputCols=[\"age\", \"genderOHE\", \"experience\"], outputCol=\"features\")\n",
    "\n",
    "# Step 5: Define a LinearRegression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"salary\")\n",
    "\n",
    "# Step 6: Create a pipeline with stages: indexer, encoder, assembler, and linear regression model\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])\n",
    "\n",
    "# Step 7: Fit the pipeline model to the data\n",
    "model = pipeline.fit(data)\n",
    "\n",
    "# Step 8: Make predictions\n",
    "predictions = model.transform(data)\n",
    "\n",
    "# Display the predictions\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrZR-mkvsQni"
   },
   "outputs": [],
   "source": [
    "#Task - write code for Eval metrics to evaluate L.R. model performance\n",
    "# pyspark documentation, stackoverflow, ChatGPT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
